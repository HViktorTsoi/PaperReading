# PointNet
http://openaccess.thecvf.com/content_cvpr_2017/papers/Qi_PointNet_Deep_Learning_CVPR_2017_paper.pdf

# PointNet++
http://papers.nips.cc/paper/7095-pointnet-deep-hierarchical-feature-learning-on-point-sets-in-a-metric-space.pdf
MSG：取不同半径的点的特征拼接在一起
MRG：高层少数点特征pool+低层对应这些少数点的多数点特征pool拼接
无序主要影响的是没有局部信息

# SehllNet
http://openaccess.thecvf.com/content_ICCV_2019/papers/Zhang_ShellNet_Efficient_Point_Cloud_Convolutional_Neural_Networks_Using_Concentric_Shells_ICCV_2019_paper.pdf

# Octree guided CNN with Spherical Kernels for 3D Point Clouds
https://arxiv.org/pdf/1903.00343.pdf

# PointCNN
邻居点feature和邻居点xyz提取的feature拼接，由于不同邻居点的顺序对生成不同的点集，学习一个排列矩阵，将邻居点顺序进行重新排列，从而实现点顺序的无关性质

# Deep Snake
Deep Snake Head：
1 输入是轮廓的N个点
2 经过多次circle conv，生成轮廓feature
3 进行1次1x1 conv，再max pooling，生成整个轮廓的全局feature(这里为什么用max pooling？汇集全局信息应该用avg pool啊)
4 再进行多次1x1 conv，得到最终的每个轮廓点的offset
用轮廓作为分割边界
1 首先生成detection的bb
2 选择bb四个中点，生成菱形
3 过一次Deep snake 生成物体的四个角点的offset(为了丰富边缘特征，实际上输入的40个点对应的feature，每个边被插值成了10个点，但是最后loss只负责监督输出的角点到bb的四角的offset)
4 分别以四个角点为中点，扩展出四条水平/垂直线(这四条线实际上就位于bb的四条边上)，其长度是bb的1/4；然后再把这四条线的两边连起来，最终构成一个八边形。这个八边形就比原来的矩形bb更好的框住了物体的轮廓，就把这个八边形作为snake的初始轮廓。
5 将这个初始轮廓采样成N个点，再送进Deep Snake，得到最终轮廓的N个offset(N一般是128)
6 重复i次步骤5(生成offset后，对原来的轮廓进行deform，然后将新轮廓采样之后再送入deep snake)，因为有的点离GT过远，需要反复进行偏移才能到GT附近
7 对于被遮挡物割裂的物体，使用multi component detector，先对Feature map做roi align，然后用一个多组件detector来检测目标，分别对每个组件做snake，最后再将轮廓合并

# Adder Net
把原来求互相关的conv转化为求L1-Norm(差的绝对值)

在bp过程中，原本的导数是sgn(X-F)，但是为了训练稳定，改为X-F，更精确；但是这个值可能太大(大于原本的+-1之间)，因此对与往前一层传的导数还要进行clip到+-1之间，使优化更稳定。

由于Adder conv的输出方差更大(见原论文)，需要借助BN来处理其输出；但是由BN的反传公式，方差越大，在BN层往前传的梯度越小，学不动了，因此需要适当增大学习率；但是通过实验发现，不同层的梯度大小分布也不同，因此不能对所有层的学习率都增大相同的倍数，而是使用了a~l~这个可调整系数，它与对应参数梯度的l2-norm成反比，也就是梯度越小，学习率相对更高，这样保证网络的不同层参数在优化时的实际更新的梯度是接近的。

# YOLO v4
## Bag of freebies
### 数据增强
随机裁剪旋转；
Random erase，CutOut；
DropOut；
MixUp，CutMix；

### 数据分布
hard example mining;
focal loss;
label smoothing;

### BBox regression
普通的BBox regression(回归角点，回归到anchor的offset)；
IOU Loss，GIOU Loss，DIOU Loss，CIOU Loss；

##  Bag of specials
### 增加感受野
SPP，ASPP，RFB；

### Attention
SEBlock,SAM;

### Feature integration
FPN,SFAM,ASFF,BiFPN;

### Activation
LReLU,PReLU,ReLU6,Swish,Mish;

### Post processing
Soft NMS；

## Backbone
需要感受野大，并且网络参数大，且输入图像够大
CSPDarknet53 + SPP + PANet + YOLOv3 Head

## 数据增强
Mosaic：就是大小为4的CutMix，找四张图像分别随机裁剪一小块下来，然后拼接在一起。这样可以让网络在被feed进一张图像时，接触到更多种类的contex的信息；另外就是BN在计算分布的时候用到了4张图像的统计信息，就不需要更大的batch size。

SAT：Self-Adversarial Training，循环执行两轮，第一轮固定网络参数训练扰动，目标是使检测结果达到最差；第二轮固定扰动正常训练网络参数，目的是在有扰动的情况下让检测结果达到最好
![title](https://raw.githubusercontent.com/HViktorTsoi/gitnote-image/master/gitnote/2020/04/24/1587724175754-1587724175834.png)

CmBN：modified CBN，将1个batch划分为4个mini batch，对每一个mini Batch，分别accumulate W，再accumulate 这个mini batch对应的BN(传统的BN是accumulate这个大的batch中所有已计算的mini batchBN)，然后normalize BN，但是不更新W和BN的参数，直到最后一个mini batch算完之后再更新参数。

modified SAM：Spatial Attention Module
modified PAN：把add换成了concat


# Grid-GCN for Fast and Scalable Point Cloud Learning
Liu et al. [26] show that the data structuring cost in three popular point-based models [22, 45, 40] is up to 88% of the overall computational cost. 

提出了Grid-GCN，Coverage-Aware Grid Query (CAGQ).
1. 首先voxelize；
2. $O_v$是所有非空voxel，从中采样M个中心voxel $O_c$；
3. 因为已经构建了point-voxel的对应关系，就可以直接从映射表中查询某个中心voxel的邻居voxel（称之为context points）；
4. 从context points中随机采样K个点，计算这K个点的重心，作为这个点分组的group center；
5. 这里有两个问题，第一个是如何选择中心voxel $O_c$，文章给出两种方法：
	1. RVS，纯随机采样
	2. CAS，Coverage-Aware采样，保证选择的点能最好的覆盖到整个空间，能覆盖到点最多的区域。具体做法是，先使用RVS随机采样M个点作为incumbent $V_I$；然后对于所有没被选择的非空voxel，依次作为challenger $V_c$，通过以下的式子(1~3)计算用$V_c$代替$V_I$所获得的覆盖率增益，如果这样做了之后能提升覆盖率，那就执行代替操作。
![title](https://raw.githubusercontent.com/HViktorTsoi/gitnote-image/master/gitnote/2020/04/29/1588093912391-1588093912392.png)
- 在这个式子中，$C_V$代表点V的邻居voxel是incumbent的数量，$\lambda$代表邻居voxel的数量。
$H_{rmv}$代表删除incumbent后减少的覆盖率，其含义就是，对于$V_I$的某个邻居V，如果V的邻居中除了$V_I$之外还有其他的incumbent，那么$C_V-1$的值一定大于0，则$\delta$就是0，这说明删除了$V_I$之后，他的附近还会有别的点来代表他，因此覆盖率不会减少；反之，如果$V_I$的邻居的邻居都没有incumbent，这说明$V_I$附近都没有代表点，那么删除他之后这个区域的覆盖率就会受到影响而降低。
- 对于$H_{add}$，只看第一项，和$H_{rmv}$是一个概念，如果$V_C$邻居的邻居没有任何incumbent，说明添加这个点会增加覆盖率，反之也成立；而第二项是一个正则项是防止过度覆盖的，就是防止对$V_C$的选择过于宽松，导致最后过多的原incumbent被替代，结果采样的点过多。
6. 如何采样这K个点，同样有2种方法：
	1. cube query，类似于ball query，但是在点云密度不均匀的时候可以覆盖更大的空间。
	2. KNN。和全局KNN不同，这个KNN只需要搜索context voxel就可以。
7.  Grid Context Aggregation：每个点的特征由以下组成：
	1. Coverage Weight，就是group center所连接的node的数量(这里有个问题，前边说了pick K node，难道这个weight不总是k吗？)；
	2. Grid Context Pooling，就是说不把中心点看做一个实际点云中的点，没有feature（实际表现应该为，不存储这个中心点的feature到query tree中），而是在计算下一层的特征时，对group center的所有node的Feature做pooling得到一个feature向量；
	3. Edge attention,像pointnet++这类的网络没有考虑edge attention，如果pointnet2的group也看做一个图的话，那么就是中心点的所有edge连接的邻居的feature经过mlp之后，直接得到映射之后的feature，每个邻居(或者说edge)的权重是相等的；而edge attention则是给每一条edge
 